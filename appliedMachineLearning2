Explore the relationship between model complexity and generalization performance by adjusting key parameters of various supervised learning models. 

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split


np.random.seed(0)
n = 15
x = np.linspace(0,10,n) + np.random.randn(n)/5
y = np.sin(x)+x/6 + np.random.randn(n)/10


X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0)

# You can use this function to help you visualize the dataset by
# plotting a scatterplot of the data points
# in the training and test sets.
def part1_scatter():
    plt.figure()
    plt.scatter(X_train, y_train, label='training data')
    plt.scatter(X_test, y_test, label='test data')
    plt.legend(loc=4);

Write a function that fits a polynomial LinearRegression model on the training data X_train for degrees 1, 3, 6, and 9. For each model, find 100 predicted values over 
the interval x = 0 to 10 (e.g. np.linspace(0,10,100)) and store this in a numpy array. The first row of this array should correspond to the output from the model 
trained on degree 1, the second row degree 3, the third row degree 6, and the fourth row degree 9.

def answer_one():
    from sklearn.linear_model import LinearRegression
    from sklearn.preprocessing import PolynomialFeatures
    # To capture interactions between the original features by adding them as features to the linear model.
    
    clf = LinearRegression() # Initialize linear classifier
    preds = np.zeros((4,100)) # Final tuple with predictions for all orders.
    X_input = np.linspace(0,10,100) # Given requirement
    orders = [1,3,6,9] # Given requirement
    
    for i in range(len(orders)):
        poly = PolynomialFeatures(orders[i]) # Object to add polynomial features.
        
        # Add polynomial features to training data and input data:
        # Need to transpose X_train and X_input for poly_fit to work.
        X_train_poly = poly.fit_transform(X_train[None].T)
        X_input_poly = poly.fit_transform(X_input[None].T)
        
        # Train linear regression classifier with training data:
        clf.fit(X_train_poly, y_train)
        
        # Get predictions from linear classifier using transformed input data:
        # This is still a weighted linear combination of features, so it's still a linear model, and can use same least-squares estimation method for w and b.
        preds[i,:] = clf.predict(X_input_poly)
    
    return preds
answer_one()

def plot_one(degree_predictions):
    plt.figure(figsize=(10,5))
    plt.plot(X_train, y_train, 'o', label='training data', markersize=10)
    plt.plot(X_test, y_test, 'o', label='test data', markersize=10)
    for i,degree in enumerate([1,3,6,9]): # i is the index of the content (used for iteration in the for loop), degree is the content.
        plt.plot(np.linspace(0,10,100), degree_predictions[i], alpha=0.8, lw=2, label='degree={}'.format(degree))
    plt.ylim(-1,2.5)
    plt.legend(loc=4)

Write a function that fits a polynomial LinearRegression model on the training data X_train for degrees 0 through 9. For each model compute the coefficient of 
determination regression score on the training data as well as the the test data, and return both of these arrays in a tuple.

def answer_two():
    from sklearn.linear_model import LinearRegression
    from sklearn.preprocessing import PolynomialFeatures
    from sklearn.metrics.regression import r2_score
    
    r2_test, r2_train = [],[]
    
    for i in range (10):
        poly = PolynomialFeatures(i)
        X_train_poly = poly.fit_transform(X_train[None].T)
        X_test_poly = poly.fit_transform(X_test[None].T)
        linreg = LinearRegression().fit(X_train_poly,y_train)
        r2_train.append(linreg.score(X_train_poly,y_train))
        r2_test.append(linreg.score(X_test_poly,y_test))
    
    return (r2_train, r2_test)

answer_two()

Based on the coefficient of determination scores from question 2 (degree levels 0 through 9), what degree level corresponds to a model that is underfitting? What 
degree level corresponds to a model that is overfitting? What choice of degree level would provide a model with good generalization performance on this dataset?

def answer_three():    
    return (0,9,6) 

answer_three()

Train two models: a non-regularized LinearRegression model (default parameters) and a regularized Lasso Regression model (with parameters alpha=0.01, max_iter=10000)
both on polynomial features of degree 12. Return the  R2R2  score for both the LinearRegression and Lasso model's test sets.

def answer_four():
    
    from sklearn.preprocessing import PolynomialFeatures
    from sklearn.linear_model import Lasso, LinearRegression
    from sklearn.metrics.regression import r2_score

    poly = PolynomialFeatures(12)
    X_train_poly = poly.fit_transform(X_train[None].T)
    X_test_poly = poly.fit_transform(X_test[None].T)
    
    linreg = LinearRegression().fit(X_train_poly,y_train)
    linlasso = Lasso(alpha=0.01,max_iter=10000).fit(X_train_poly,y_train)
    
    # Asked to find score for TEST SET!
    return (linreg.score(X_test_poly,y_test),linlasso.score(X_test_poly,y_test))

answer_four()

For this section of the assignment we will be working with the UCI Mushroom Data Set stored in readonly/mushrooms.csv. The data will be used to train a model to 
predict whether or not a mushroom is poisonous. The data in the mushrooms dataset is currently encoded with strings. These values will need to be encoded to numeric 
to work with sklearn. We'll use pd.get_dummies to convert the categorical variables into indicator variables.

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

mush_df = pd.read_csv('mushrooms.csv')
mush_df2 = pd.get_dummies(mush_df)

X_mush = mush_df2.iloc[:,2:]
y_mush = mush_df2.iloc[:,1]

# use the variables X_train2, y_train2 for Question 5
X_train2, X_test2, y_train2, y_test2 = train_test_split(X_mush, y_mush, random_state=0)

# For performance reasons in Questions 6 and 7, we will create a smaller version of the
# entire mushroom dataset for use in those questions.  For simplicity we'll just re-use
# the 25% test split created above as the representative subset.
#
# Use the variables X_subset, y_subset for Questions 6 and 7.
X_subset = X_test2
y_subset = y_test2

#mush_df

Using X_train2 and y_train2 from the preceeding cell, train a DecisionTreeClassifier with default parameters and random_state=0. What are the 5 most important 
features found by the decision tree?

def answer_five():
    
    from sklearn.tree import DecisionTreeClassifier
    clf = DecisionTreeClassifier(random_state=0).fit(X_train2,y_train2)
    df = pd.DataFrame({'feature':X_train2.columns.values, 'feature importance': clf.feature_importances_})
    return df.sort(['feature importance'],ascending=0)['feature'].head(5).tolist()

answer_five()

Use the validation_curve function in sklearn.model_selection to determine training and test scores for a Support Vector Classifier (SVC) with varying parameter 
values. Use the variables X_subset and y_subset as input to the validation curve function (instead of X_mush and y_mush) to reduce computation time.

For each level of `gamma`, `validation_curve` will fit 3 models on different subsets of the data, returning two 6x3 (6 levels of gamma x 3 fits per level) arrays of 
the scores for the training and test sets. Find the mean score across the three models for each level of `gamma` for both arrays, creating two arrays of length 6, 
and return a tuple with the two arrays.

def answer_six():
    
    from sklearn.svm import SVC
    from sklearn.model_selection import validation_curve
    
    # RBF kernel and C=1 are default anyway.
    param_range = np.logspace(-4,1,6)
    train_scores, test_scores = validation_curve(SVC(random_state=0),X_subset,y_subset,param_name='gamma',param_range=param_range)
    
    # Finds row-wise mean (i.e mean across column values).
    return np.array(list(map(np.mean,train_scores))),np.array(list(map(np.mean,test_scores)))

answer_six()

Based on the scores from question 6, what gamma value corresponds to a model that is underfitting (and has the worst test set accuracy)? What gamma value corresponds
to a model that is overfitting (and has the worst test set accuracy)? What choice of gamma would be the best choice for a model with good generalization performance 
on this dataset (high accuracy on both training and test set)?

def answer_seven():
    
    #train_scores, test_scores = answer_six()
    #plt.figure()
    #plt.plot(np.logspace(-4,1,6),train_scores,'b',label='Training scores')
    #plt.plot(np.logspace(-4,1,6),test_scores,'r',label='Test scores')
    #plt.xscale('log') # Sets x axis to a log scale.
    #plt.xlabel('Gamma')
    #plt.ylabel('Scores')
    #plt.legend()
    
    return (0.0001,10,0.1) 

answer_seven()

