In this assignment you will train several models and evaluate how effectively they predict instances of fraud using data based on this dataset from Kaggle.
Each row in fraud_data.csv corresponds to a credit card transaction. Features include confidential variables V1 through V28 as well as Amount which is the amount of the
transaction.

import numpy as np
import pandas as pd

def answer_one():
    
    df = pd.read_csv('fraud_data.csv')
    seg = df.iloc[:,-1]
    return float(seg[seg.values==1].count()/seg.count())

answer_one()

# Use X_train, X_test, y_train, y_test for all of the following questions
from sklearn.model_selection import train_test_split

df = pd.read_csv('fraud_data.csv')

X = df.iloc[:,:-1]
y = df.iloc[:,-1]

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)

Using X_train, X_test, y_train, and y_test (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is 
the accuracy of this classifier? What is the recall?

def answer_two():
    from sklearn.dummy import DummyClassifier
    from sklearn.metrics import recall_score
    
    dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train,y_train)
    y_dummy_pred = dummy_majority.predict(X_test)
    return (dummy_majority.score(X_train,y_train),recall_score(y_test,y_dummy_pred))

answer_two()

Using X_train, X_test, y_train, y_test (as defined above), train a SVC classifer using the default parameters. What is the accuracy, recall, and precision of this 
classifier?

def answer_three():
    from sklearn.metrics import recall_score, precision_score
    from sklearn.svm import SVC

    clf = SVC(kernel='rbf').fit(X_train,y_train)
    pred = clf.predict(X_test)
    return (clf.score(X_train,y_train),recall_score(y_test,pred),precision_score(y_test,pred))

answer_three()

Using the SVC classifier with parameters {'C': 1e9, 'gamma': 1e-07}, what is the confusion matrix when using a threshold of -220 on the decision function. Use X_test 
and y_test.

def answer_four():
    from sklearn.metrics import confusion_matrix
    from sklearn.svm import SVC

    svm = SVC(C=1e9,gamma=1e-07).fit(X_train,y_train)
    y_pred = svm.decision_function(X_test) > -220
    return confusion_matrix(y_test,y_pred)

answer_four()

Train a logisitic regression classifier with default parameters using X_train and y_train.
For the logisitic regression classifier, create a precision recall curve and a roc curve using y_test and the probability estimates for X_test (probability it is 
fraud).
Looking at the precision recall curve, what is the recall when the precision is 0.75?
Looking at the roc curve, what is the true positive rate when the false positive rate is 0.16?

def answer_five():
        
    #%matplotlib notebook
    #import matplotlib.pyplot as plt
    from sklearn.linear_model import LogisticRegression
    from sklearn.metrics import precision_recall_curve, roc_curve
    
    y_scores_lr = LogisticRegression().fit(X_train,y_train).decision_function(X_test)
    precision,recall,thresholds = precision_recall_curve(y_test,y_scores_lr)
    fpr_lr, tpr_lr, _ = roc_curve(y_test, y_scores_lr)
    
    #plt.figure()
    #plt.plot(precision,recall)
    #plt.plot(fpr_lr,tpr_lr)
    
    return (0.83,0.94)

answer_five()

Perform a grid search over the parameters listed below for a Logisitic Regression classifier, using recall for scoring and the default 3-fold cross validation.

From .cv_results_, create an array of the mean test scores of each parameter combination.

def answer_six():    
    from sklearn.model_selection import GridSearchCV
    from sklearn.linear_model import LogisticRegression

    grid_values={'penalty': ['l1', 'l2'], 'C':[0.01, 0.1, 1, 10, 100]}
    lr = LogisticRegression().fit(X_train,y_train)
    
    # Number of folds included as a parameter in GridSearchCV. Default cv=3.
    lr_custom = GridSearchCV(lr,param_grid=grid_values,scoring='recall',cv=3)
    lr_custom.fit(X_train,y_train)

    return lr_custom.cv_results_['mean_test_score'].reshape(5,2)

answer_six()

# Use the following function to help visualize results from the grid search
def GridSearch_Heatmap(scores):
    %matplotlib notebook
    import seaborn as sns
    import matplotlib.pyplot as plt
    plt.figure()
    sns.heatmap(scores.reshape(5,2), xticklabels=['l1','l2'], yticklabels=[0.01, 0.1, 1, 10, 100])
    plt.yticks(rotation=0);

#GridSearch_Heatmap(answer_six())
