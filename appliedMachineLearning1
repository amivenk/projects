Use the Breast Cancer Wisconsin (Diagnostic) Database to create a classifier that can help diagnose patients.

import numpy as np
import pandas as pd
from sklearn.datasets import load_breast_cancer

cancer = load_breast_cancer()
cancer.keys()

How many features does the breast cancer dataset have?

def answer_zero():
return len(cancer['feature_names'])
answer_zero() 

Convert the sklearn.dataset cancer to a DataFrame.

This function should return a (569, 31) DataFrame with

columns =

['mean radius', 'mean texture', 'mean perimeter', 'mean area',
'mean smoothness', 'mean compactness', 'mean concavity',
'mean concave points', 'mean symmetry', 'mean fractal dimension',
'radius error', 'texture error', 'perimeter error', 'area error',
'smoothness error', 'compactness error', 'concavity error',
'concave points error', 'symmetry error', 'fractal dimension error',
'worst radius', 'worst texture', 'worst perimeter', 'worst area',
'worst smoothness', 'worst compactness', 'worst concavity',
'worst concave points', 'worst symmetry', 'worst fractal dimension',
'target']
and index =

RangeIndex(start=0, stop=569, step=1)

def answer_one():
    columns = np.append(cancer.feature_names, 'target');   
    print("Features Column Size: " + str(np.size(columns)))
    index = pd.RangeIndex(start=0, stop=569, step=1);
    data = np.column_stack((cancer.data, cancer.target))
    print("Data Column Size: " + str(np.size(data) / 569))
    df = pd.DataFrame(data=data, index=index, columns=columns)
    
    return df

answer_one()

What is the class distribution?

def answer_two():
    cancerdf = answer_one()
    
    index = ['malignant', 'benign']
    malignants = np.where(cancerdf['target'] == 0.0);
    benings = np.where(cancerdf['target'] == 1.0);
    data = [np.size(malignants), np.size(benings)]
    print(data)
    series = pd.Series(data, index=index)
    
    return series # Return your answer


answer_two()

Split the DataFrame into X (the data) and y (the labels).

This function should return a tuple of length 2: (X, y), where

X, a pandas DataFrame, has shape (569, 30)
y, a pandas Series, has shape (569,).

def answer_three():
    cancerdf = answer_one()
    
    # Your code here
    # Drop target column, axis=1 means drop column with given name, axis=0 means drop row.
    X = cancerdf.drop('target', axis=1)
    y = cancerdf.get('target')
    
    return X, y
    
Using `train_test_split`, split `X` and `y` into training and test sets `(X_train, X_test, y_train, and y_test)`.
*This function should return a tuple of length 4:* `(X_train, X_test, y_train, y_test)`*, where* 
* `X_train` *has shape* `(426, 30)`
* `X_test` *has shape* `(143, 30)`
* `y_train` *has shape* `(426,)`
* `y_test` *has shape* `(143,)`

from sklearn.model_selection import train_test_split

def answer_four():
    X, y = answer_three()
    
    # Your code here
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
    
    return X_train, X_test, y_train, y_test
    
Using KNeighborsClassifier, fit a k-nearest neighbors (knn) classifier with X_train, y_train and using one nearest neighbor (n_neighbors = 1).

from sklearn.neighbors import KNeighborsClassifier

def answer_five():
    X_train, X_test, y_train, y_test = answer_four()
    
    # Your code here
    knn = KNeighborsClassifier(n_neighbors = 1)
    knn.fit(X_train, y_train)
    knn.score(X_test, y_test)
    
    return knn 

Using your knn classifier, predict the class label using the mean value for each feature.

def answer_six():
    cancerdf = answer_one()
    means = cancerdf.mean()[:-1].values.reshape(1, -1)
    
    # Your code here
    knn = answer_five()
    
    return knn.predict(means)

Using your knn classifier, predict the class labels for the test set X_test.

def answer_seven():
    X_train, X_test, y_train, y_test = answer_four()
    knn = answer_five()
    
    test_prediction = knn.predict(X_test)
    
    return test_prediction

Find the score (mean accuracy) of your knn classifier using X_test and y_test.

def answer_eight():
    X_train, X_test, y_train, y_test = answer_four()
    knn = answer_five()
    
    # Your code here
    score = knn.score(X_test, y_test)
    print("Accuracy: " + str(score))
    
    prediction = answer_six()
    print("Going to be cancer: " + str())
    
    return score

Try using the plotting function below to visualize the different prediction scores between training and test sets, as well as malignant and benign cells.

def accuracy_plot():
    import matplotlib.pyplot as plt

    %matplotlib notebook

    X_train, X_test, y_train, y_test = answer_four()

    # Find the training and testing accuracies by target value (i.e. malignant, benign)
    mal_train_X = X_train[y_train==0]
    mal_train_y = y_train[y_train==0]
    ben_train_X = X_train[y_train==1]
    ben_train_y = y_train[y_train==1]

    mal_test_X = X_test[y_test==0]
    mal_test_y = y_test[y_test==0]
    ben_test_X = X_test[y_test==1]
    ben_test_y = y_test[y_test==1]

    knn = answer_five()

    scores = [knn.score(mal_train_X, mal_train_y), knn.score(ben_train_X, ben_train_y), 
              knn.score(mal_test_X, mal_test_y), knn.score(ben_test_X, ben_test_y)]
              
    plt.figure()

    # Plot the scores as a bar chart
    bars = plt.bar(np.arange(4), scores, color=['#4c72b0','#4c72b0','#55a868','#55a868'])

    # directly label the score onto the bars
    for bar in bars:
        height = bar.get_height()
        plt.gca().text(bar.get_x() + bar.get_width()/2, height*.90, '{0:.{1}f}'.format(height, 2), 
                     ha='center', color='w', fontsize=11)

    # remove all the ticks (both axes), and tick labels on the Y axis
    plt.tick_params(top='off', bottom='off', left='off', right='off', labelleft='off', labelbottom='on')

    # remove the frame of the chart
    for spine in plt.gca().spines.values():
        spine.set_visible(False)

    plt.xticks([0,1,2,3], ['Malignant\nTraining', 'Benign\nTraining', 'Malignant\nTest', 'Benign\nTest'], alpha=0.8);
    plt.title('Training and Test Accuracies for Malignant and Benign Cells', alpha=0.8)
